{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f36dee81",
   "metadata": {},
   "source": [
    "# PySuricata — Pandas Example\n",
    "\n",
    "This notebook demonstrates how to use PySuricata with pandas DataFrames."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13626dbf",
   "metadata": {},
   "source": [
    "## 1. Installation\n",
    "\n",
    "```bash\n",
    "pip install pysuricata\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a504a45b",
   "metadata": {},
   "source": [
    "## 2. Basic Report\n",
    "\n",
    "Generate a full HTML report from any pandas DataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b7f95fac",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-14T13:54:47.602155Z",
     "iopub.status.busy": "2026-02-14T13:54:47.602043Z",
     "iopub.status.idle": "2026-02-14T13:54:48.028056Z",
     "shell.execute_reply": "2026-02-14T13:54:48.027699Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 891 rows × 12 columns\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pysuricata import profile\n",
    "\n",
    "# Load the Titanic dataset\n",
    "url = \"https://raw.githubusercontent.com/datasciencedojo/datasets/master/titanic.csv\"\n",
    "df = pd.read_csv(url)\n",
    "print(f\"Loaded {len(df)} rows × {len(df.columns)} columns\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5d1e45d8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-14T13:54:48.029091Z",
     "iopub.status.busy": "2026-02-14T13:54:48.029023Z",
     "iopub.status.idle": "2026-02-14T13:54:48.093961Z",
     "shell.execute_reply": "2026-02-14T13:54:48.093610Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Report saved to titanic_report.html\n"
     ]
    }
   ],
   "source": [
    "# Generate and save the report\n",
    "report = profile(df)\n",
    "report.save_html(\"titanic_report.html\")\n",
    "print(\"Report saved to titanic_report.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b97a2802",
   "metadata": {},
   "source": [
    "## 3. Statistics Only (No HTML)\n",
    "\n",
    "Use `summarize()` when you just need the numbers — great for CI/CD pipelines:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ce4892e7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-14T13:54:48.094924Z",
     "iopub.status.busy": "2026-02-14T13:54:48.094870Z",
     "iopub.status.idle": "2026-02-14T13:54:48.136333Z",
     "shell.execute_reply": "2026-02-14T13:54:48.136034Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows: 891\n",
      "Columns: 12\n",
      "Missing cells: 8.1%\n",
      "Duplicate rows (est): 0.0%\n"
     ]
    }
   ],
   "source": [
    "from pysuricata import summarize\n",
    "\n",
    "stats = summarize(df)\n",
    "\n",
    "# Dataset-level metrics\n",
    "print(f\"Rows: {stats['dataset']['rows_est']}\")\n",
    "print(f\"Columns: {stats['dataset']['cols']}\")\n",
    "print(f\"Missing cells: {stats['dataset']['missing_cells_pct']:.1f}%\")\n",
    "print(f\"Duplicate rows (est): {stats['dataset']['duplicate_rows_pct_est']:.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6a33cb02",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-14T13:54:48.137194Z",
     "iopub.status.busy": "2026-02-14T13:54:48.137138Z",
     "iopub.status.idle": "2026-02-14T13:54:48.138798Z",
     "shell.execute_reply": "2026-02-14T13:54:48.138451Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  PassengerId           type=numeric       missing=0.0%\n",
      "  Survived              type=categorical   missing=0.0%\n",
      "  Pclass                type=categorical   missing=0.0%\n",
      "  Name                  type=categorical   missing=0.0%\n",
      "  Sex                   type=categorical   missing=0.0%\n",
      "  Age                   type=numeric       missing=0.0%\n",
      "  SibSp                 type=categorical   missing=0.0%\n",
      "  Parch                 type=categorical   missing=0.0%\n",
      "  Ticket                type=categorical   missing=0.0%\n",
      "  Fare                  type=numeric       missing=0.0%\n",
      "  Cabin                 type=categorical   missing=0.0%\n",
      "  Embarked              type=categorical   missing=0.0%\n"
     ]
    }
   ],
   "source": [
    "# Column-level metrics\n",
    "for col_name, col_stats in stats[\"columns\"].items():\n",
    "    col_type = col_stats.get(\"type\", \"unknown\")\n",
    "    missing = col_stats.get(\"missing_pct\", 0)\n",
    "    print(f\"  {col_name:20s}  type={col_type:12s}  missing={missing:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94994924",
   "metadata": {},
   "source": [
    "## 4. Custom Configuration\n",
    "\n",
    "Tune chunk sizes, sample sizes, and correlation thresholds:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fe1707b5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-14T13:54:48.139668Z",
     "iopub.status.busy": "2026-02-14T13:54:48.139606Z",
     "iopub.status.idle": "2026-02-14T13:54:48.191429Z",
     "shell.execute_reply": "2026-02-14T13:54:48.191065Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Custom report saved\n"
     ]
    }
   ],
   "source": [
    "from pysuricata import profile, ReportConfig\n",
    "\n",
    "config = ReportConfig()\n",
    "config.compute.chunk_size = 500          # rows per chunk\n",
    "config.compute.random_seed = 42          # reproducible results\n",
    "config.compute.compute_correlations = True\n",
    "config.compute.corr_threshold = 0.5      # only show strong correlations\n",
    "config.render.title = \"Titanic Analysis\"\n",
    "\n",
    "report = profile(df, config=config)\n",
    "report.save_html(\"titanic_custom.html\")\n",
    "print(\"Custom report saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91b54d2e",
   "metadata": {},
   "source": [
    "## 5. Streaming Large Datasets\n",
    "\n",
    "Process datasets larger than RAM by passing a chunk generator:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "175bf034",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-14T13:54:48.192396Z",
     "iopub.status.busy": "2026-02-14T13:54:48.192334Z",
     "iopub.status.idle": "2026-02-14T13:54:48.193992Z",
     "shell.execute_reply": "2026-02-14T13:54:48.193708Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Streaming is supported via generators — see docs for details\n"
     ]
    }
   ],
   "source": [
    "def read_in_chunks(path, chunk_size=10_000):\n",
    "    \"\"\"Yield chunks from a large CSV without loading it all into memory.\"\"\"\n",
    "    for chunk in pd.read_csv(path, chunksize=chunk_size):\n",
    "        yield chunk\n",
    "\n",
    "# Example (using the same small file for demo purposes)\n",
    "# report = profile(read_in_chunks(\"large_dataset.csv\"))\n",
    "# report.save_html(\"large_report.html\")\n",
    "print(\"Streaming is supported via generators — see docs for details\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28f3522a",
   "metadata": {},
   "source": [
    "## 6. Quality Gate Example\n",
    "\n",
    "Use `summarize()` in CI to enforce data quality thresholds:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c519da63",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-14T13:54:48.194828Z",
     "iopub.status.busy": "2026-02-14T13:54:48.194778Z",
     "iopub.status.idle": "2026-02-14T13:54:48.235417Z",
     "shell.execute_reply": "2026-02-14T13:54:48.235093Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All quality gates passed ✓\n"
     ]
    }
   ],
   "source": [
    "stats = summarize(df)\n",
    "\n",
    "# Define quality gates\n",
    "assert stats[\"dataset\"][\"missing_cells_pct\"] < 20.0, \"Too many missing values!\"\n",
    "assert stats[\"dataset\"][\"duplicate_rows_pct_est\"] < 5.0, \"Too many duplicates!\"\n",
    "\n",
    "print(\"All quality gates passed ✓\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
