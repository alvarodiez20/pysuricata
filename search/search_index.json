{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"PySuricata","text":"<p>Generate clean, self-contained EDA reports for pandas and large CSV/Parquet files.</p> <p>Tip</p> <p>Works great on small and medium datasets; for very large datasets, sample first.</p>"},{"location":"#features","title":"Features","text":"<ul> <li>Summary stats, missingness, duplicates</li> <li>Numeric, categorical, datetime, and boolean cards with inline SVG charts</li> <li>Out-of-core streaming (CSV/Parquet) with low peak memory</li> <li>Approximate distinct counts and heavy hitters for large columns</li> <li>Streaming correlations for numeric columns</li> <li>Self-contained HTML export (inline CSS/JS/images)</li> </ul>"},{"location":"#quick-links","title":"Quick links","text":"<ul> <li>Installation</li> <li>Usage</li> </ul>"},{"location":"#quick-start","title":"Quick start","text":"Classic (in-memory)Streaming (v2) <pre><code>import pandas as pd\nfrom pysuricata.report import generate_report\n\ndf = pd.read_csv(\"/path/to/data.csv\")\nhtml = generate_report(df, report_title=\"My EDA\")\n</code></pre> <pre><code>from pysuricata.report_v2 import generate_report, ReportConfig\n\nhtml = generate_report(\n    source=\"/path/to/data.parquet\",  # or .csv\n    config=ReportConfig(chunk_size=250_000, compute_correlations=True),\n    output_file=\"report.html\",\n)\n</code></pre>"},{"location":"#how-it-works-v2","title":"How it works (v2)","text":"<ul> <li>Reads input in chunks (pandas for CSV, pyarrow for Parquet) and feeds type-specific accumulators.</li> <li>Numeric accumulators maintain Welford/P\u00e9bay moments, a reservoir sample, and KMV distinct.</li> <li>Categorical accumulators use Misra\u2013Gries for top-k and KMV for distinct.</li> <li>Datetime accumulators count by hour/day/month and keep min/max.</li> <li>A lightweight streaming correlation estimator tracks Pearson r for numeric pairs.</li> <li>The template renders a self-contained HTML with precise duration (e.g., 0.02s) and processed bytes (\u2248).</li> </ul> <p>See also: Numeric analysis details in numeric_var.md.</p>"},{"location":"architecture/","title":"Architecture &amp; Internals","text":"<p>This document explains how <code>pysuricata</code> (especially <code>report_v2</code>) profiles data efficiently and renders a self\u2011contained HTML report.</p>"},{"location":"architecture/#overview","title":"Overview","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 Source \u2502 \u2192 \u2502 Chunk iterator\u2502 \u2192 \u2502 Typed accumulators \u2502 \u2192 \u2502 HTML template \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n     CSV / Parquet / DataFrame      numeric / categorical / datetime / boolean\n</code></pre>"},{"location":"architecture/#chunk-ingestion","title":"Chunk ingestion","text":"<ul> <li>CSV: uses <code>pandas.read_csv(..., chunksize=N)</code> (low\u2011memory mode).</li> <li>Parquet: uses <code>pyarrow.parquet.ParquetFile.iter_batches(batch_size=N)</code> and converts batches to pandas for normalization.</li> <li>DataFrame: treated as a single chunk.</li> </ul>"},{"location":"architecture/#typed-accumulators","title":"Typed accumulators","text":"<p>Each column kind is handled by a specialized accumulator with small, mergeable state:</p> <ul> <li>NumericAccumulator</li> <li>Moments (n, mean, M2, M3, M4) via Welford/P\u00e9bay (exact, mergeable)</li> <li>Min/Max, zeros, negatives, \u00b1inf, missing counters</li> <li>Reservoir sample (default 20k) for quantiles, histograms, and shape hints</li> <li>KMV (K\u2011Minimum Values) for approximate distinct</li> <li>Misra\u2013Gries top\u2011k for discrete integer\u2011like columns (on demand)</li> <li>Heaping %, granularity (decimals/step), bimodality hint</li> <li>Streaming correlation chips (optional, numeric vs numeric)</li> <li> <p>Extremes with row indices (min / max tracked across chunks)</p> </li> <li> <p>CategoricalAccumulator</p> </li> <li>KMV for distinct, Misra\u2013Gries for top\u2011k</li> <li>String length stats (avg, p90), empty strings</li> <li> <p>Case/trim variant distinctness</p> </li> <li> <p>DatetimeAccumulator</p> </li> <li>Min/Max timestamps (ns), counts by hour / day of week / month</li> <li> <p>Monotonicity hints</p> </li> <li> <p>BooleanAccumulator</p> </li> <li>True/False counts, missing, imbalance hints</li> </ul> <p>All accumulators expose <code>update(...)</code> and <code>finalize() \u2192 SummaryDataclass</code> for rendering.</p>"},{"location":"architecture/#streaming-correlations","title":"Streaming correlations","text":"<p><code>_StreamingCorr</code> maintains pairwise sufficient statistics for numeric columns and emits top absolute correlations above a configurable threshold for each column.</p>"},{"location":"architecture/#rendering-pipeline","title":"Rendering pipeline","text":"<ol> <li>Infer column kinds from the first chunk.</li> <li>Build accumulators and consume the first chunk.</li> <li>Consume remaining chunks, update streaming correlations if enabled.</li> <li>Compute summary metrics (missingness, duplicates, constant columns, etc.).</li> <li>Render the template with:</li> <li>Summary cards (rows, cols, processed bytes (\u2248), missing/duplicates)</li> <li>Top missing columns</li> <li>Variables (cards by type)</li> <li>Optional dataset sample</li> </ol> <p>The template is a single file with inline CSS/JS/images to produce a portable HTML.</p>"},{"location":"architecture/#configuration","title":"Configuration","text":"<p><code>ReportConfig</code> controls chunk size, sample sizes, distinct/top\u2011k sketch sizes, and correlation settings, plus logging and checkpointing.</p> <p>Key fields:</p> <ul> <li><code>chunk_size</code>: rows per chunk (default 200k)</li> <li><code>numeric_sample_k</code>: reservoir size for numeric sampling (default 20k)</li> <li><code>uniques_k</code>: KMV sketch size (default 2048)</li> <li><code>topk_k</code>: Misra\u2013Gries capacity (default 50)</li> <li><code>compute_correlations</code>: enable/disable streaming correlation chips</li> <li><code>corr_threshold</code>, <code>corr_max_cols</code>, <code>corr_max_per_col</code></li> <li><code>include_sample</code>, <code>sample_rows</code></li> <li>Checkpointing: write periodic pickles and (optional) partial HTML</li> </ul>"},{"location":"architecture/#processed-bytes-timing","title":"Processed bytes &amp; timing","text":"<p>The report shows: - Processed bytes (\u2248): cumulative bytes processed across chunks (not process RSS) - Precise generation time in seconds (e.g., <code>0.02s</code>)</p>"},{"location":"architecture/#security-correctness-notes","title":"Security &amp; correctness notes","text":"<ul> <li>HTML escaping: column names, labels, and chip text are escaped before rendering.</li> <li>Missing/inf handling: NaN and \u00b1Inf are excluded from moment calculations but reported separately.</li> <li>Approximation badges: estimates are marked with <code>(\u2248)</code> or an <code>approx</code> badge.</li> </ul>"},{"location":"architecture/#extending","title":"Extending","text":"<ul> <li>Add backends: polars/Arrow datasets or DuckDB scans can be plugged into the chunk iterator.</li> <li>Add quantile sketches: t\u2011digest or KLL can replace the default reservoir for better tail accuracy.</li> <li>Add new sections: drift comparisons, profile JSON export to file, CLI wrapper.</li> </ul>"},{"location":"install/","title":"Installation","text":"<pre><code>pip install pysuricata\n</code></pre>"},{"location":"numeric_var/","title":"Numerical Variable Analysis","text":"<p>TL;DR: This page defines exact and approximate statistics for numerical columns, the incremental formulas we use (Welford/P\u00e9bay), how we build histograms and quantiles (exact, KLL, t\u2011digest), outlier rules (z\u2011score, IQR, MAD), and the guarantees, complexity, and configuration knobs.</p> <p>Audience</p> <p>Designed for users who want to understand and trust the numbers in the HTML report as well as contributors who need to modify the accumulator implementations.</p>"},{"location":"numeric_var/#scope","title":"Scope","text":"<p><code>pysuricata</code> treats a numerical variable as any column with a machine type among <code>{int8, int16, int32, int64, float32, float64, decimal}</code> (nullable). Values may include <code>NaN</code>, <code>\u00b1Inf</code>, and missing markers.</p> <p>We report global statistics and (optionally) windowed ones (e.g., per\u2011file chunk, per time window in a stream). All stats are computed incrementally via stateful accumulators so that we can process datasets larger than RAM.</p>"},{"location":"numeric_var/#summary-cards-what-youll-see-in-the-report","title":"Summary cards (what you\u2019ll see in the report)","text":"<ul> <li>Count (non\u2011null), missing %, distinct (exact/approx), min, max</li> <li>Central tendency: mean, median</li> <li>Dispersion: variance, standard deviation, IQR, MAD</li> <li>Shape: skewness, excess kurtosis</li> <li>Quantiles (configurable set) and histogram preview</li> <li>Outlier flags (IQR fences and modified z\u2011score)</li> </ul> <p>All numbers are derived from the algorithms below and are reproducible when re\u2011run with the same config and data.</p>"},{"location":"numeric_var/#mathematical-definitions","title":"Mathematical definitions","text":""},{"location":"numeric_var/#notation","title":"Notation","text":"<p>Let \\(x_1, x_2, \\ldots, x_n\\) be the non\u2011missing observations for a column.</p> <ul> <li>Mean: \\(\\bar{x} = \\frac{1}{n}\\sum_{i=1}^{n} x_i\\)</li> <li>Unbiased sample variance: \\(s^2 = \\frac{1}{n-1}\\sum_{i=1}^{n} (x_i-\\bar{x})^2\\)</li> <li>Std. deviation: \\(s = \\sqrt{s^2}\\)</li> <li>Median: any \\(m\\) such that half the mass is \\(\\le m\\) and half \\(\\ge m\\)</li> <li>Quantile \\(Q(p)\\): infimum \\(q\\) with CDF \\(\\ge p\\)</li> <li>IQR: \\(Q(0.75) - Q(0.25)\\)</li> <li>MAD: \\(\\operatorname{median}(|x_i - \\operatorname{median}(x)|)\\)</li> <li>Skewness (g\u2081):   [   g_1 = \\frac{n}{(n-1)(n-2)} \\cdot \\frac{\\frac{1}{n}\\sum (x_i-\\bar{x})^3}{s^3}   ]</li> <li>Excess kurtosis (g\u2082):   [   g_2 = \\frac{n(n+1)}{(n-1)(n-2)(n-3)} \\cdot \\frac{\\frac{1}{n}\\sum (x_i-\\bar{x})^4}{s^4} - \\frac{3(n-1)^2}{(n-2)(n-3)}   ]</li> </ul>"},{"location":"numeric_var/#outlier-rules","title":"Outlier rules","text":"<ul> <li>IQR fences: an observation is an outlier if \\(x &lt; Q(0.25) - 1.5\\,\\mathrm{IQR}\\) or \\(x &gt; Q(0.75) + 1.5\\,\\mathrm{IQR}\\). 3.0 is a common \u201cextreme\u201d fence.</li> <li>Modified z\u2011score (robust): \\(M_i = 0.6745\\,\\frac{x_i - \\operatorname{median}(x)}{\\operatorname{MAD}}\\). Flag if \\(|M_i| &gt; 3.5\\).</li> <li>Z\u2011score (classical): \\(Z_i = \\frac{x_i - \\bar{x}}{s}\\). Sensitive to non\u2011normality and outliers.</li> </ul>"},{"location":"numeric_var/#incremental-mergeable-estimation-how-we-compute-at-scale","title":"Incremental &amp; mergeable estimation (how we compute at scale)","text":"<p>We maintain running central moments using Welford\u2019s method with P\u00e9bay\u2019s parallel merge formulas so we can:</p> <ul> <li>update statistics in O(1) per observation</li> <li>merge partial results from multiple chunks/threads/nodes exactly (up to FP rounding)</li> </ul>"},{"location":"numeric_var/#online-update-for-n-mean-m2-m3-m4","title":"Online update for (n, mean, M2, M3, M4)","text":"<p>For a new value \\(x\\) and previous state \\((n, \\mu, M_2, M_3, M_4)\\):</p> \\[ \\begin{aligned}  n' &amp;= n + 1 \\\\  \\delta &amp;= x - \\mu \\\\  \\delta_n &amp;= \\frac{\\delta}{n'} \\\\  \\delta_n^2 &amp;= \\delta_n^2 \\\\  \\mu' &amp;= \\mu + \\delta_n \\\\  M_4' &amp;= M_4 + \\delta(\\delta^3 \\frac{n(n-1)}{n'^3} + 6\\,\\delta_n M_2' - 4\\,\\delta_n^2 M_3) \\\\  M_3' &amp;= M_3 + \\delta(\\delta^2 \\frac{n(n-1)}{n'^2} - 3\\,\\delta_n M_2) \\\\  M_2' &amp;= M_2 + \\delta(\\delta - \\delta_n) \\end{aligned} \\] <p>Then: \\(s^2 = M_2'/(n'-1)\\), and shape statistics are computed from \\(M_2', M_3', M_4'\\) as in the definitions above.</p> <p>Numerical stability: this form avoids catastrophic cancellation found in two\u2011pass formulas.</p>"},{"location":"numeric_var/#parallelchunked-merge-pebay","title":"Parallel/Chunked merge (P\u00e9bay)","text":"<p>Given two partial states \\(A=(n_a, \\mu_a, M_{2a}, M_{3a}, M_{4a})\\) and \\(B=(n_b, \\mu_b, M_{2b}, M_{3b}, M_{4b})\\), define \\(\\delta = \\mu_b - \\mu_a\\), \\(n = n_a + n_b\\). Then (abridged):</p> \\[ \\begin{aligned} \\mu &amp;= \\mu_a + \\delta \\cdot \\frac{n_b}{n} \\\\ M_2 &amp;= M_{2a} + M_{2b} + \\delta^2 \\cdot \\frac{n_a n_b}{n} \\\\ M_3 &amp;= M_{3a} + M_{3b} + \\delta^3 \\cdot \\frac{n_a n_b (n_a - n_b)}{n^2} + 3\\delta \\cdot \\frac{n_a M_{2b} - n_b M_{2a}}{n} \\\\ M_4 &amp;= M_{4a} + M_{4b} + \\delta^4 \\cdot \\frac{n_a n_b (n_a^2 - n_a n_b + n_b^2)}{n^3} \\\\ &amp;\\quad + 6\\delta^2 \\cdot \\frac{n_a n_b}{n^2}(n_a M_{2b} + n_b M_{2a}) + 4\\delta \\cdot \\frac{n_a M_{3b} - n_b M_{3a}}{n} \\end{aligned} \\] <p>These enable exact merges of chunked/parallel passes.</p> References <ul> <li>Welford\u2019s online mean/variance \u2014 Wikipedia: https://en.wikipedia.org/wiki/Algorithms_for_calculating_variance#Welford's_online_algorithm</li> <li>P\u00e9bay, Formulas for Robust, One\u2011Pass Parallel Computation of Covariances and Statistical Moments, Sandia Report SAND2008\u20116212: https://prod-ng.sandia.gov/techlib-noauth/access-control.cgi/2008/086212.pdf</li> </ul>"},{"location":"numeric_var/#quantiles-histograms","title":"Quantiles &amp; histograms","text":"ExactApproximate (default for large data) <ul> <li>Quantiles: maintain a reservoir sample or, for in\u2011memory small columns, sort all values and index by \\(\\lceil p(n+1) \\rceil\\) with linear interpolation.</li> <li>Histogram: fixed binning with computed bin width. Default bin count uses Freedman\u2013Diaconis:   [ h = 2\\,\\frac{\\mathrm{IQR}}{n^{1/3}} \\quad\\Rightarrow\\quad k = \\left\\lceil \\frac{\\max - \\min}{h} \\right\\rceil. ]</li> <li>Pros: exact; Cons: may be expensive for very large \\(n\\).</li> </ul> <ul> <li>KLL sketch for quantiles \u2014 sublinear memory with provable error bounds.</li> <li>t\u2011digest (optional) \u2014 excellent tail accuracy for percentiles like P99.</li> <li>Streaming histogram \u2014 fold approximate quantiles into dynamic bins.</li> </ul> <p>References: - KLL: Optimal Quantile Approximation in Streams \u2014 https://arxiv.org/abs/1603.05346 - t\u2011digest (Dunning &amp; Ertl) \u2014 https://arxiv.org/abs/1902.04023 - Freedman\u2013Diaconis rule \u2014 https://en.wikipedia.org/wiki/Freedman%E2%80%93Diaconis_rule</p>"},{"location":"numeric_var/#distinct-counts-optional","title":"Distinct counts (optional)","text":"<p>For numerical columns with many repeated values (e.g., codes, rounded measures) we can report distinct and top\u2011k. For large domains we offer:</p> <ul> <li>HyperLogLog for approximate distinct with small, fixed memory.</li> <li>Space\u2011Saving for top\u2011k heavy hitters.</li> </ul> <p>References: HLL (Flajolet et al.) \u2014 https://algo.inria.fr/flajolet/Publications/FlFuGaMe07.pdf, Space\u2011Saving \u2014 https://www.cs.ucdavis.edu/~minle/paper/summary.pdf</p>"},{"location":"numeric_var/#missing-nan-and-inf-handling","title":"Missing, NaN, and Inf handling","text":"<ul> <li>Missing: values recognized as nulls are excluded from moment calculations; we still report <code>missing_count</code> and <code>missing_pct</code>.</li> <li>NaN: treated as missing.</li> <li>\u00b1Inf: excluded from moments but counted under a dedicated <code>infinite_count</code> and surfaced in warnings.</li> <li>Type coercion: strings that parse to numbers are counted only if parsing is enabled.</li> </ul> <p>Edge cases</p> <p>All\u2011missing columns, or columns with \\(n&lt;2\\), will have undefined variance/shape; we report <code>null</code> and document why.</p>"},{"location":"numeric_var/#computation-guarantees-complexity","title":"Computation guarantees &amp; complexity","text":"<ul> <li>Time: \\(O(n)\\) total, \\(O(1)\\) amortized per value for moments; sketches are \\(O(\\log(1/\\varepsilon))\\) per update.</li> <li>Space: \\(O(1)\\) for moments; sketches use tens to thousands of bytes depending on accuracy.</li> <li>Determinism: merges are associative up to IEEE\u2011754 rounding; we use stable orders where feasible.</li> </ul>"},{"location":"numeric_var/#configuration","title":"Configuration","text":"Python APICLIEnv vars <pre><code>from pysuricata import profile\n\nreport = profile(\n    df,\n    numeric={\n        \"quantiles\": [0.01, 0.05, 0.25, 0.5, 0.75, 0.95, 0.99],\n        \"hist\": {\"strategy\": \"fd\", \"max_bins\": 256},\n        \"sketch\": {\"quantiles\": \"kll\", \"tdigest\": {\"delta\": 1000}},\n        \"distinct\": {\"method\": \"hll\", \"precision\": 14},\n        \"outliers\": {\"method\": \"iqr|mad|zscore\", \"fence\": 1.5},\n        \"nan_policy\": \"exclude\",\n    }\n)\n</code></pre> <pre><code>pysuricata report data.parquet \\\n  --quantiles 0.01 0.05 0.5 0.95 0.99 \\\n  --hist fd --hist-max-bins 256 \\\n  --qsketch kll --tdigest-delta 1000 \\\n  --distinct hll --hll-precision 14 \\\n  --outliers mad --fence 3.5\n</code></pre> <pre><code>export PS_NUMERIC_Q=0.01,0.05,0.5,0.95,0.99\nexport PS_HIST_STRATEGY=fd\nexport PS_HIST_MAX_BINS=256\nexport PS_QSKETCH=kll\n</code></pre> <p>Note: Exact option names may evolve. See the Python docstrings for authoritative signatures.</p>"},{"location":"numeric_var/#api-surface-accumulators","title":"API surface (accumulators)","text":"<pre><code>class NumericAccumulator:\n    \"\"\"Stateful, mergeable accumulator for one numerical column.\"\"\"\n\n    def update(self, values):\n        \"\"\"Update running moments and sketches from an array/Series.\"\"\"\n\n    def merge(self, other):\n        \"\"\"Parallel merge (P\u00e9bay).\"\"\"\n\n    def finalize(self):\n        \"\"\"Return a dataclass with count, missing, mean, s, skew, kurtosis, min, max, quantiles, histogram, outliers.\"\"\"\n</code></pre> <p>Minimal usage</p> <pre><code>import pandas as pd\nfrom pysuricata.numeric import NumericAccumulator\n\nacc = NumericAccumulator()\nfor chunk in pd.read_csv(\"data.csv\", chunksize=200_000):\n    acc.update(chunk[\"amount\"].to_numpy())\nsummary = acc.finalize()\n</code></pre>"},{"location":"numeric_var/#validation","title":"Validation","text":"<ul> <li>Cross\u2011check against <code>numpy</code>, <code>scipy.stats</code>, and <code>pandas</code> on small datasets.</li> <li>Property\u2011based tests: invariants under concatenation (merge == single pass), scaling/translation laws.</li> <li>Randomized FP tests to catch catastrophic cancellation.</li> </ul>"},{"location":"numeric_var/#see-also","title":"See also","text":"<ul> <li>Skewness and kurtosis \u2014 https://en.wikipedia.org/wiki/Skewness, https://en.wikipedia.org/wiki/Kurtosis</li> <li>MAD &amp; robust stats \u2014 https://en.wikipedia.org/wiki/Median_absolute_deviation</li> <li>IQR &amp; Tukey fences \u2014 https://en.wikipedia.org/wiki/Interquartile_range</li> </ul>"},{"location":"numeric_var/#changelog","title":"Changelog","text":"<ul> <li>v0.1: initial draft of numerical analysis module and documentation.</li> </ul>"},{"location":"usage/","title":"Usage","text":""},{"location":"usage/#classic-in-memory-dataframe","title":"Classic (in-memory DataFrame)","text":"<pre><code>import pandas as pd\nfrom pysuricata.report import generate_report\n\ndf = pd.read_csv(\"data.csv\")\nhtml = generate_report(df, report_title=\"My EDA\")\nwith open(\"report.html\", \"w\", encoding=\"utf-8\") as f:\n    f.write(html)\n</code></pre>"},{"location":"usage/#streaming-v2-for-large-csvparquet","title":"Streaming (v2) for large CSV/Parquet","text":"<pre><code>from pysuricata.report_v2 import generate_report, ReportConfig\n\ncfg = ReportConfig(\n    chunk_size=250_000,\n    compute_correlations=True,  # enable streaming correlation chips for numeric columns\n)\n\n# From a file path (CSV/Parquet)\nhtml = generate_report(\"/data/big.parquet\", config=cfg, output_file=\"report.html\")\n\n# From a DataFrame in-memory (single chunk)\nimport pandas as pd\ndf = pd.read_csv(\"/data/sample.csv\")\nhtml = generate_report(df, config=cfg)\n</code></pre>"},{"location":"usage/#programmatic-summary","title":"Programmatic summary","text":"<p>Ask the generator to return a compact JSON-like dictionary alongside the HTML:</p> <pre><code>html, summary = generate_report(\"/data/big.csv\", config=cfg, return_summary=True)\nprint(summary[\"dataset\"])           # rows_est, cols, missing_cells, duplicates, top-missing\nprint(summary[\"columns\"][\"amount\"]) # per-column stats by type\n</code></pre>"},{"location":"usage/#processed-bytes-and-timing","title":"Processed bytes and timing","text":"<p>The v2 report displays: - Processed bytes (\u2248): total bytes handled across chunks (not peak RSS) - Precise generation time in seconds (e.g., 0.02s)</p>"},{"location":"usage/#chart-builder-helpers","title":"Chart builder helpers","text":"<p>You can also render the small SVGs programmatically:</p> <pre><code>from pysuricata.report_v2 import (\n    build_hist_svg_with_axes,\n    build_cat_bar_svg,\n    build_dt_line_svg,\n)\n\nhist_svg = build_hist_svg_with_axes(df[\"amount\"], bins=25)\ncat_svg = build_cat_bar_svg(df[\"country\"], top=10)\ndt_svg = build_dt_line_svg(df[\"ts\"], bins=60)\n</code></pre>"}]}