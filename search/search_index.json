{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"PySuricata","text":"<p>Generate clean, self-contained EDA reports for pandas/polars DataFrames and large in-memory chunked iterables.</p> <p>Tip</p> <p>Works great on small and medium datasets; for very large datasets, sample first.</p>"},{"location":"#features","title":"Features","text":"<ul> <li>Summary stats, missingness, duplicates</li> <li>Numeric, categorical, datetime, and boolean cards with inline SVG charts</li> <li>Out-of-core streaming for in-memory DataFrame chunks (low peak memory)</li> <li>Approximate distinct counts and heavy hitters for large columns</li> <li>Streaming correlations for numeric columns</li> <li>Self-contained HTML export (inline CSS/JS/images)</li> </ul>"},{"location":"#quick-links","title":"Quick links","text":"<ul> <li>Installation</li> <li>Usage</li> <li>API</li> <li>Architecture</li> </ul>"},{"location":"#quick-start","title":"Quick start","text":"<pre><code>import pandas as pd\nfrom pysuricata import profile, ReportConfig\n\ndf = pd.read_csv(\"/path/to/data.csv\")\nrep = profile(df, config=ReportConfig())\nrep.save_html(\"report.html\")\n\n# Or stream in-memory chunks you create\ndef chunk_iter():\n    for i in range(10):\n        yield pd.read_csv(f\"/data/part-{i}.csv\")\n\nrep = profile((ch for ch in chunk_iter()), config=ReportConfig())\nrep.save_html(\"report.html\")\n</code></pre>"},{"location":"#how-it-works","title":"How it works","text":"<ul> <li>Reads input in chunks (pandas DataFrames) and feeds type-specific accumulators.</li> <li>Numeric accumulators maintain Welford/P\u00e9bay moments, a reservoir sample, and KMV distinct.</li> <li>Categorical accumulators use Misra\u2013Gries for top-k and KMV for distinct.</li> <li>Datetime accumulators count by hour/day/month and keep min/max.</li> <li>A lightweight streaming correlation estimator tracks Pearson r for numeric pairs.</li> <li>The template renders a self-contained HTML with precise duration (e.g., 0.02s) and processed bytes (\u2248).</li> <li>Deterministic visuals via <code>ReportConfig.compute.random_seed</code>.</li> </ul> <p>See also: Numeric analysis details in numeric_var.md.</p>"},{"location":"api/","title":"High-level API","text":"<p>The unified API exposes two entry points that cover most workflows:</p> <ul> <li><code>profile(data, config=None) -&gt; Report</code>: compute + HTML</li> <li><code>summarize(data, config=None) -&gt; Mapping[str, Any]</code>: stats-only</li> </ul> <p>Import from the package root:</p> <pre><code>from pysuricata import profile, summarize, ReportConfig\n</code></pre>"},{"location":"api/#inputs","title":"Inputs","text":"<ul> <li>In-memory <code>pandas.DataFrame</code></li> <li><code>polars.DataFrame</code> or <code>LazyFrame</code></li> <li>Iterable/generator yielding pandas DataFrame chunks (you control chunking)</li> </ul>"},{"location":"api/#report-object","title":"Report object","text":"<pre><code>from pysuricata import profile, ReportConfig\n\nrep = profile(df, config=ReportConfig())\nrep.save_html(\"report.html\")\nrep.save_json(\"report.json\")\n\n# In notebooks, the report displays inline\nrep\n</code></pre>"},{"location":"api/#quick-render","title":"Quick render","text":"<pre><code>rep = profile(df)\nrep.save_html(\"report.html\")\n</code></pre>"},{"location":"api/#stats-only-cidata-quality","title":"Stats-only (CI/data-quality)","text":"<pre><code>stats = summarize(df)  # compute-only fast path (skips HTML)\n\n# Example: assert no column has &gt; 10% missing\nbad = [\n    (name, col[\"missing\"]) for name, col in stats[\"columns\"].items()\n    if col.get(\"missing\", 0) / max(1, col.get(\"count\", 0)) &gt; 0.10\n]\nassert not bad, f\"Columns too missing: {bad}\"\n</code></pre>"},{"location":"api/#configuration","title":"Configuration","text":"<p>The top-level <code>ReportConfig</code> wraps compute and render options:</p> <pre><code>from pysuricata import ReportConfig\n\ncfg = ReportConfig()\ncfg.compute.chunk_size = 250_000\ncfg.compute.columns = [\"a\", \"b\", \"c\"]\ncfg.compute.numeric_sample_size = 50_000\ncfg.compute.max_uniques = 4096\ncfg.compute.top_k = 100\ncfg.compute.random_seed = 42  # deterministic sampling\n\nrep = profile(df, config=cfg)\n</code></pre>"},{"location":"api/#load-and-chunk-outside","title":"Load and chunk outside","text":"<p>You can read data with any library and either pass a single DataFrame or an iterable of DataFrames you manage:</p> <pre><code>import pandas as pd\nfrom pysuricata import profile\n\ndef chunk_iter():\n    for i in range(10):\n        yield pd.read_parquet(f\"/data/part-{i}.parquet\")\n\nrep = profile((ch for ch in chunk_iter()))\n</code></pre>"},{"location":"api/#common-use-cases","title":"Common use cases","text":"<ul> <li> <p>Small DataFrame (in-memory):   <pre><code>import pandas as pd\nfrom pysuricata import profile\ndf = pd.DataFrame({\"x\": [1,2,3], \"y\": [\"a\",\"b\",\"a\"]})\nrep = profile(df)\n</code></pre></p> </li> <li> <p>Large dataset (streaming in-memory):   <pre><code>from pysuricata import ReportConfig, profile\ncfg = ReportConfig(); cfg.compute.chunk_size = 250_000\nrep = profile((ch for ch in chunk_iter()), config=cfg)\nrep.save_html(\"report.html\")\n</code></pre></p> </li> <li> <p>Column selection:   <pre><code>from pysuricata import ReportConfig, summarize\ncfg = ReportConfig()\ncfg.compute.columns = [\"id\", \"amount\", \"ts\"]\nstats = summarize(df[[\"id\", \"amount\", \"ts\"]])\n</code></pre></p> </li> <li> <p>CI check: enforce low duplicates and missingness:   <pre><code>stats = summarize(df)\nds = stats[\"dataset\"]\nassert ds[\"duplicate_rows_pct_est\"] &lt; 1.0\nassert ds[\"missing_cells_pct\"] &lt; 5.0\n</code></pre></p> </li> </ul>"},{"location":"api/#notes-and-limits","title":"Notes and limits","text":"<ul> <li>Current engine consumes pandas or polars DataFrames (or iterables of pandas frames). Polars eager/LazyFrames are processed natively.</li> <li>Render options are minimal; the HTML template is self-contained (light theme).</li> </ul>"},{"location":"api/#determinism","title":"Determinism","text":"<p>Set <code>cfg.compute.random_seed</code> to make reservoir sampling and other RNG use deterministic. This stabilizes histogram shapes in tests and CI.</p>"},{"location":"architecture/","title":"Architecture &amp; Internals","text":"<p>This document explains how <code>pysuricata</code> profiles data efficiently and renders a self\u2011contained HTML report.</p>"},{"location":"architecture/#overview","title":"Overview","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 Source \u2502 \u2192 \u2502 Chunk iterator\u2502 \u2192 \u2502 Typed accumulators \u2502 \u2192 \u2502 HTML template \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n     In-memory DataFrame(s)          numeric / categorical / datetime / boolean\n</code></pre>"},{"location":"architecture/#chunk-ingestion","title":"Chunk ingestion","text":"<ul> <li>Iterable of pandas DataFrames: consumed as-is.</li> <li>Single pandas DataFrame: treated as one chunk (or sliced by rows if you pre-split it).</li> </ul>"},{"location":"architecture/#typed-accumulators","title":"Typed accumulators","text":"<p>Each column kind is handled by a specialized accumulator with small, mergeable state:</p> <ul> <li>NumericAccumulator</li> <li>Moments (n, mean, M2, M3, M4) via Welford/P\u00e9bay (exact, mergeable)</li> <li>Min/Max, zeros, negatives, \u00b1inf, missing counters</li> <li>Reservoir sample (default 20k) for quantiles, histograms, and shape hints</li> <li>KMV (K\u2011Minimum Values) for approximate distinct</li> <li>Misra\u2013Gries top\u2011k for discrete integer\u2011like columns (on demand)</li> <li>Heaping %, granularity (decimals/step), bimodality hint</li> <li>Streaming correlation chips (optional, numeric vs numeric)</li> <li> <p>Extremes with row indices (min / max tracked across chunks)</p> </li> <li> <p>CategoricalAccumulator</p> </li> <li>KMV for distinct, Misra\u2013Gries for top\u2011k</li> <li>String length stats (avg, p90), empty strings</li> <li> <p>Case/trim variant distinctness</p> </li> <li> <p>DatetimeAccumulator</p> </li> <li>Min/Max timestamps (ns), counts by hour / day of week / month</li> <li> <p>Monotonicity hints</p> </li> <li> <p>BooleanAccumulator</p> </li> <li>True/False counts, missing, imbalance hints</li> </ul> <p>All accumulators expose <code>update(...)</code> and <code>finalize() \u2192 SummaryDataclass</code> for rendering.</p>"},{"location":"architecture/#streaming-correlations","title":"Streaming correlations","text":"<p><code>_StreamingCorr</code> maintains pairwise sufficient statistics for numeric columns and emits top absolute correlations above a configurable threshold for each column.</p>"},{"location":"architecture/#rendering-pipeline","title":"Rendering pipeline","text":"<ol> <li>Infer column kinds from the first chunk.</li> <li>Build accumulators and consume the first chunk.</li> <li>Consume remaining chunks, update streaming correlations if enabled.</li> <li>Compute summary metrics (missingness, duplicates, constant columns, etc.).</li> <li>Render the template with:</li> <li>Summary cards (rows, cols, processed bytes (\u2248), missing/duplicates)</li> <li>Top missing columns</li> <li>Variables (cards by type)</li> <li>Optional dataset sample</li> </ol> <p>The template is a single file with inline CSS/JS/images to produce a portable HTML.</p>"},{"location":"architecture/#shared-helpers-deduped","title":"Shared helpers (deduped)","text":"<p>Rendering utilities live in two small modules for reuse and testability:</p> <ul> <li><code>pysuricata/render/svg_utils.py</code></li> <li><code>safe_col_id</code>, <code>nice_ticks</code>, <code>fmt_tick</code>, <code>svg_empty</code></li> <li><code>pysuricata/render/format_utils.py</code></li> <li><code>human_bytes</code>, <code>fmt_num</code>, <code>fmt_compact</code></li> </ul> <p>These power both the main report and the individual variable cards with consistent tick/label formatting.</p>"},{"location":"architecture/#configuration","title":"Configuration","text":"<p><code>ReportConfig</code> controls chunk size, sample sizes, distinct/top\u2011k sketch sizes, and correlation settings, plus logging and checkpointing. It also exposes <code>random_seed</code> to make sampling deterministic for reproducible visuals.</p> <p>Key fields:</p> <ul> <li><code>chunk_size</code>: rows per chunk (default 200k)</li> <li><code>numeric_sample_k</code>: reservoir size for numeric sampling (default 20k)</li> <li><code>uniques_k</code>: KMV sketch size (default 2048)</li> <li><code>topk_k</code>: Misra\u2013Gries capacity (default 50)</li> <li><code>compute_correlations</code>: enable/disable streaming correlation chips</li> <li><code>corr_threshold</code>, <code>corr_max_cols</code>, <code>corr_max_per_col</code></li> <li><code>include_sample</code>, <code>sample_rows</code></li> <li>Checkpointing: write periodic pickles and (optional) partial HTML</li> </ul>"},{"location":"architecture/#processed-bytes-timing","title":"Processed bytes &amp; timing","text":"<p>The report shows: - Processed bytes (\u2248): cumulative bytes processed across chunks (not process RSS) - Precise generation time in seconds (e.g., <code>0.02s</code>)</p>"},{"location":"architecture/#security-correctness-notes","title":"Security &amp; correctness notes","text":"<ul> <li>HTML escaping: column names, labels, and chip text are escaped before rendering.</li> <li>Missing/inf handling: NaN and \u00b1Inf are excluded from moment calculations but reported separately.</li> <li>Approximation badges: estimates are marked with <code>(\u2248)</code> or an <code>approx</code> badge.</li> </ul>"},{"location":"architecture/#extending","title":"Extending","text":"<ul> <li>Add backends: polars/Arrow datasets or DuckDB scans can be plugged into the chunk iterator.</li> <li>Add quantile sketches: t\u2011digest or KLL can replace the default reservoir for better tail accuracy.</li> <li>Add new sections: drift comparisons, profile JSON export to file, CLI wrapper.</li> </ul>"},{"location":"install/","title":"Installation","text":"<p>Install from PyPI:</p> <pre><code>pip install pysuricata\n</code></pre> <p>Optional: install <code>polars</code> to use polars DataFrames directly:</p> <pre><code>pip install polars\n</code></pre> <p>Verify your installation:</p> <pre><code>&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; from pysuricata import profile\n&gt;&gt;&gt; df = pd.DataFrame({\"x\": [1, 2, 3]})\n&gt;&gt;&gt; profile(df).html[:15]\n'&lt;!DOCTYPE html&gt;'\n</code></pre>"},{"location":"numeric_var/","title":"Numerical Variable Analysis","text":"<p>TL;DR: This page defines exact and approximate statistics for numerical columns, the incremental formulas we use (Welford/P\u00e9bay), how we build histograms and quantiles (exact, KLL, t\u2011digest), outlier rules (z\u2011score, IQR, MAD), and the guarantees, complexity, and configuration knobs.</p> <p>Audience</p> <p>Designed for users who want to understand and trust the numbers in the HTML report as well as contributors who need to modify the accumulator implementations.</p>"},{"location":"numeric_var/#scope","title":"Scope","text":"<p><code>pysuricata</code> treats a numerical variable as any column with a machine type among <code>{int8, int16, int32, int64, float32, float64, decimal}</code> (nullable). Values may include <code>NaN</code>, <code>\u00b1Inf</code>, and missing markers.</p> <p>We report global statistics and (optionally) windowed ones (e.g., per\u2011file chunk, per time window in a stream). All stats are computed incrementally via stateful accumulators so that we can process datasets larger than RAM.</p>"},{"location":"numeric_var/#summary-cards-what-youll-see-in-the-report","title":"Summary cards (what you\u2019ll see in the report)","text":"<ul> <li>Count (non\u2011null), missing %, distinct (exact/approx), min, max</li> <li>Central tendency: mean, median</li> <li>Dispersion: variance, standard deviation, IQR, MAD</li> <li>Shape: skewness, excess kurtosis</li> <li>Quantiles (configurable set) and histogram preview</li> <li>Outlier flags (IQR fences and modified z\u2011score)</li> </ul> <p>All numbers are derived from the algorithms below and are reproducible when re\u2011run with the same config and data.</p>"},{"location":"numeric_var/#mathematical-definitions","title":"Mathematical definitions","text":""},{"location":"numeric_var/#notation","title":"Notation","text":"<p>Let \\(x_1, x_2, \\ldots, x_n\\) be the non\u2011missing observations for a column.</p> <ul> <li>Mean: \\(\\bar{x} = \\frac{1}{n}\\sum_{i=1}^{n} x_i\\)</li> <li>Unbiased sample variance: \\(s^2 = \\frac{1}{n-1}\\sum_{i=1}^{n} (x_i-\\bar{x})^2\\)</li> <li>Std. deviation: \\(s = \\sqrt{s^2}\\)</li> <li>Median: any \\(m\\) such that half the mass is \\(\\le m\\) and half \\(\\ge m\\)</li> <li>Quantile \\(Q(p)\\): infimum \\(q\\) with CDF \\(\\ge p\\)</li> <li>IQR: \\(Q(0.75) - Q(0.25)\\)</li> <li>MAD: \\(\\operatorname{median}(|x_i - \\operatorname{median}(x)|)\\)</li> <li>Skewness (g\u2081):   [   g_1 = \\frac{n}{(n-1)(n-2)} \\cdot \\frac{\\frac{1}{n}\\sum (x_i-\\bar{x})^3}{s^3}   ]</li> <li>Excess kurtosis (g\u2082):   [   g_2 = \\frac{n(n+1)}{(n-1)(n-2)(n-3)} \\cdot \\frac{\\frac{1}{n}\\sum (x_i-\\bar{x})^4}{s^4} - \\frac{3(n-1)^2}{(n-2)(n-3)}   ]</li> </ul>"},{"location":"numeric_var/#outlier-rules","title":"Outlier rules","text":"<ul> <li>IQR fences: an observation is an outlier if \\(x &lt; Q(0.25) - 1.5\\,\\mathrm{IQR}\\) or \\(x &gt; Q(0.75) + 1.5\\,\\mathrm{IQR}\\). 3.0 is a common \u201cextreme\u201d fence.</li> <li>Modified z\u2011score (robust): \\(M_i = 0.6745\\,\\frac{x_i - \\operatorname{median}(x)}{\\operatorname{MAD}}\\). Flag if \\(|M_i| &gt; 3.5\\).</li> <li>Z\u2011score (classical): \\(Z_i = \\frac{x_i - \\bar{x}}{s}\\). Sensitive to non\u2011normality and outliers.</li> </ul>"},{"location":"numeric_var/#incremental-mergeable-estimation-how-we-compute-at-scale","title":"Incremental &amp; mergeable estimation (how we compute at scale)","text":"<p>We maintain running central moments using Welford\u2019s method with P\u00e9bay\u2019s parallel merge formulas so we can:</p> <ul> <li>update statistics in O(1) per observation</li> <li>merge partial results from multiple chunks/threads/nodes exactly (up to FP rounding)</li> </ul>"},{"location":"numeric_var/#online-update-for-n-mean-m2-m3-m4","title":"Online update for (n, mean, M2, M3, M4)","text":"<p>For a new value \\(x\\) and previous state \\((n, \\mu, M_2, M_3, M_4)\\):</p> \\[ \\begin{aligned}  n' &amp;= n + 1 \\\\  \\delta &amp;= x - \\mu \\\\  \\delta_n &amp;= \\frac{\\delta}{n'} \\\\  \\delta_n^2 &amp;= \\delta_n^2 \\\\  \\mu' &amp;= \\mu + \\delta_n \\\\  M_4' &amp;= M_4 + \\delta(\\delta^3 \\frac{n(n-1)}{n'^3} + 6\\,\\delta_n M_2' - 4\\,\\delta_n^2 M_3) \\\\  M_3' &amp;= M_3 + \\delta(\\delta^2 \\frac{n(n-1)}{n'^2} - 3\\,\\delta_n M_2) \\\\  M_2' &amp;= M_2 + \\delta(\\delta - \\delta_n) \\end{aligned} \\] <p>Then: \\(s^2 = M_2'/(n'-1)\\), and shape statistics are computed from \\(M_2', M_3', M_4'\\) as in the definitions above.</p> <p>Numerical stability: this form avoids catastrophic cancellation found in two\u2011pass formulas.</p>"},{"location":"numeric_var/#parallelchunked-merge-pebay","title":"Parallel/Chunked merge (P\u00e9bay)","text":"<p>Given two partial states \\(A=(n_a, \\mu_a, M_{2a}, M_{3a}, M_{4a})\\) and \\(B=(n_b, \\mu_b, M_{2b}, M_{3b}, M_{4b})\\), define \\(\\delta = \\mu_b - \\mu_a\\), \\(n = n_a + n_b\\). Then (abridged):</p> \\[ \\begin{aligned} \\mu &amp;= \\mu_a + \\delta \\cdot \\frac{n_b}{n} \\\\ M_2 &amp;= M_{2a} + M_{2b} + \\delta^2 \\cdot \\frac{n_a n_b}{n} \\\\ M_3 &amp;= M_{3a} + M_{3b} + \\delta^3 \\cdot \\frac{n_a n_b (n_a - n_b)}{n^2} + 3\\delta \\cdot \\frac{n_a M_{2b} - n_b M_{2a}}{n} \\\\ M_4 &amp;= M_{4a} + M_{4b} + \\delta^4 \\cdot \\frac{n_a n_b (n_a^2 - n_a n_b + n_b^2)}{n^3} \\\\ &amp;\\quad + 6\\delta^2 \\cdot \\frac{n_a n_b}{n^2}(n_a M_{2b} + n_b M_{2a}) + 4\\delta \\cdot \\frac{n_a M_{3b} - n_b M_{3a}}{n} \\end{aligned} \\] <p>These enable exact merges of chunked/parallel passes.</p> References <ul> <li>Welford\u2019s online mean/variance \u2014 Wikipedia: https://en.wikipedia.org/wiki/Algorithms_for_calculating_variance#Welford's_online_algorithm</li> <li>P\u00e9bay, Formulas for Robust, One\u2011Pass Parallel Computation of Covariances and Statistical Moments, Sandia Report SAND2008\u20116212: https://prod-ng.sandia.gov/techlib-noauth/access-control.cgi/2008/086212.pdf</li> </ul>"},{"location":"numeric_var/#quantiles-histograms","title":"Quantiles &amp; histograms","text":"ExactApproximate (default for large data) <ul> <li>Quantiles: maintain a reservoir sample or, for in\u2011memory small columns, sort all values and index by \\(\\lceil p(n+1) \\rceil\\) with linear interpolation.</li> <li>Histogram: fixed binning with computed bin width. Default bin count uses Freedman\u2013Diaconis:   [ h = 2\\,\\frac{\\mathrm{IQR}}{n^{1/3}} \\quad\\Rightarrow\\quad k = \\left\\lceil \\frac{\\max - \\min}{h} \\right\\rceil. ]</li> <li>Pros: exact; Cons: may be expensive for very large \\(n\\).</li> </ul> <ul> <li>KLL sketch for quantiles \u2014 sublinear memory with provable error bounds.</li> <li>t\u2011digest (optional) \u2014 excellent tail accuracy for percentiles like P99.</li> <li>Streaming histogram \u2014 fold approximate quantiles into dynamic bins.</li> </ul> <p>References: - KLL: Optimal Quantile Approximation in Streams \u2014 https://arxiv.org/abs/1603.05346 - t\u2011digest (Dunning &amp; Ertl) \u2014 https://arxiv.org/abs/1902.04023 - Freedman\u2013Diaconis rule \u2014 https://en.wikipedia.org/wiki/Freedman%E2%80%93Diaconis_rule</p>"},{"location":"numeric_var/#distinct-counts-optional","title":"Distinct counts (optional)","text":"<p>For numerical columns with many repeated values (e.g., codes, rounded measures) we can report distinct and top\u2011k. For large domains we offer:</p> <ul> <li>HyperLogLog for approximate distinct with small, fixed memory.</li> <li>Space\u2011Saving for top\u2011k heavy hitters.</li> </ul> <p>References: HLL (Flajolet et al.) \u2014 https://algo.inria.fr/flajolet/Publications/FlFuGaMe07.pdf, Space\u2011Saving \u2014 https://www.cs.ucdavis.edu/~minle/paper/summary.pdf</p>"},{"location":"numeric_var/#missing-nan-and-inf-handling","title":"Missing, NaN, and Inf handling","text":"<ul> <li>Missing: values recognized as nulls are excluded from moment calculations; we still report <code>missing_count</code> and <code>missing_pct</code>.</li> <li>NaN: treated as missing.</li> <li>\u00b1Inf: excluded from moments but counted under a dedicated <code>infinite_count</code> and surfaced in warnings.</li> <li>Type coercion: strings that parse to numbers are counted only if parsing is enabled.</li> </ul> <p>Edge cases</p> <p>All\u2011missing columns, or columns with \\(n&lt;2\\), will have undefined variance/shape; we report <code>null</code> and document why.</p>"},{"location":"numeric_var/#computation-guarantees-complexity","title":"Computation guarantees &amp; complexity","text":"<ul> <li>Time: \\(O(n)\\) total, \\(O(1)\\) amortized per value for moments; sketches are \\(O(\\log(1/\\varepsilon))\\) per update.</li> <li>Space: \\(O(1)\\) for moments; sketches use tens to thousands of bytes depending on accuracy.</li> <li>Determinism: merges are associative up to IEEE\u2011754 rounding; we use stable orders where feasible.</li> </ul>"},{"location":"numeric_var/#configuration","title":"Configuration","text":"Python APICLIEnv vars <pre><code>from pysuricata import profile\n\nreport = profile(\n    df,\n    numeric={\n        \"quantiles\": [0.01, 0.05, 0.25, 0.5, 0.75, 0.95, 0.99],\n        \"hist\": {\"strategy\": \"fd\", \"max_bins\": 256},\n        \"sketch\": {\"quantiles\": \"kll\", \"tdigest\": {\"delta\": 1000}},\n        \"distinct\": {\"method\": \"hll\", \"precision\": 14},\n        \"outliers\": {\"method\": \"iqr|mad|zscore\", \"fence\": 1.5},\n        \"nan_policy\": \"exclude\",\n    }\n)\n</code></pre> <pre><code>pysuricata report data.parquet \\\n  --quantiles 0.01 0.05 0.5 0.95 0.99 \\\n  --hist fd --hist-max-bins 256 \\\n  --qsketch kll --tdigest-delta 1000 \\\n  --distinct hll --hll-precision 14 \\\n  --outliers mad --fence 3.5\n</code></pre> <pre><code>export PS_NUMERIC_Q=0.01,0.05,0.5,0.95,0.99\nexport PS_HIST_STRATEGY=fd\nexport PS_HIST_MAX_BINS=256\nexport PS_QSKETCH=kll\n</code></pre> <p>Note: Exact option names may evolve. See the Python docstrings for authoritative signatures.</p>"},{"location":"numeric_var/#api-surface-accumulators","title":"API surface (accumulators)","text":"<pre><code>class NumericAccumulator:\n    \"\"\"Stateful, mergeable accumulator for one numerical column.\"\"\"\n\n    def update(self, values):\n        \"\"\"Update running moments and sketches from an array/Series.\"\"\"\n\n    def merge(self, other):\n        \"\"\"Parallel merge (P\u00e9bay).\"\"\"\n\n    def finalize(self):\n        \"\"\"Return a dataclass with count, missing, mean, s, skew, kurtosis, min, max, quantiles, histogram, outliers.\"\"\"\n</code></pre> <p>Minimal usage</p> <pre><code>import pandas as pd\nfrom pysuricata.numeric import NumericAccumulator\n\nacc = NumericAccumulator()\nfor chunk in pd.read_csv(\"data.csv\", chunksize=200_000):\n    acc.update(chunk[\"amount\"].to_numpy())\nsummary = acc.finalize()\n</code></pre>"},{"location":"numeric_var/#validation","title":"Validation","text":"<ul> <li>Cross\u2011check against <code>numpy</code>, <code>scipy.stats</code>, and <code>pandas</code> on small datasets.</li> <li>Property\u2011based tests: invariants under concatenation (merge == single pass), scaling/translation laws.</li> <li>Randomized FP tests to catch catastrophic cancellation.</li> </ul>"},{"location":"numeric_var/#see-also","title":"See also","text":"<ul> <li>Skewness and kurtosis \u2014 https://en.wikipedia.org/wiki/Skewness, https://en.wikipedia.org/wiki/Kurtosis</li> <li>MAD &amp; robust stats \u2014 https://en.wikipedia.org/wiki/Median_absolute_deviation</li> <li>IQR &amp; Tukey fences \u2014 https://en.wikipedia.org/wiki/Interquartile_range</li> </ul>"},{"location":"numeric_var/#changelog","title":"Changelog","text":"<ul> <li>v0.1: initial draft of numerical analysis module and documentation.</li> </ul>"},{"location":"usage/","title":"Usage","text":""},{"location":"usage/#basic","title":"Basic","text":"<pre><code>import pandas as pd\nfrom pysuricata import profile\n\ndf = pd.read_csv(\"data.csv\")\nrep = profile(df)\nrep.save_html(\"report.html\")\n</code></pre>"},{"location":"usage/#also-save-stats-as-json","title":"Also save stats as JSON","text":"<pre><code>from pysuricata import profile\n\nrep = profile(df)\nrep.save_json(\"report.json\")\n</code></pre>"},{"location":"usage/#streaming-large-in-memory-data","title":"Streaming large in-memory data","text":"<pre><code>from pysuricata import profile, ReportConfig\nimport pandas as pd\n\ncfg = ReportConfig()\n\n# From an iterable/generator yielding pandas DataFrame chunks\ndef chunk_iter():\n    for i in range(10):\n        yield pd.read_csv(f\"/data/part-{i}.csv\")  # you pre-chunk externally\n\nrep = profile((ch for ch in chunk_iter()), config=cfg)\nrep.save_html(\"report.html\")\n</code></pre>"},{"location":"usage/#streaming-polars","title":"Streaming polars","text":"<pre><code>import polars as pl\nfrom pysuricata import profile\n\ndf = pl.read_parquet(\"/data/big.parquet\")\nrep = profile(df)  # eager or LazyFrame supported\nrep.save_html(\"report.html\")\n</code></pre>"},{"location":"usage/#streaming-with-polars-iterables-and-lazyframe","title":"Streaming with polars iterables and LazyFrame","text":"<p>Keep Polars end\u2011to\u2011end. The engine consumes either Pandas or Polars chunks.</p> <p>Iterable of Polars DataFrames:</p> <pre><code>import polars as pl\nfrom pysuricata import profile, ReportConfig\n\ndf = pl.DataFrame({\n    \"a\": list(range(100_000)),\n    \"b\": [float(i) if i % 5 else None for i in range(100_000)],\n})\n\nstep = 20_000\nchunks = (df.slice(i, min(step, df.height - i)) for i in range(0, df.height, step))\nrep = profile(chunks, config=ReportConfig())\nrep.save_html(\"polars_iterable_report.html\")\n</code></pre> <p>Polars LazyFrame (windowed collect under the hood):</p> <pre><code>import polars as pl\nfrom pysuricata import profile, ReportConfig, ComputeOptions\n\nlf = (\n    pl.LazyFrame({\n        \"x\": list(range(200_000)),\n        \"y\": [float(i) if i % 7 else None for i in range(200_000)],\n        \"z\": [\"a\" if i % 2 else \"b\" for i in range(200_000)],\n    })\n    .with_columns(pl.col(\"x\") * 2)\n)\n\ncfg = ReportConfig(compute=ComputeOptions(chunk_size=50_000))\nrep = profile(lf, config=cfg)\nrep.save_html(\"polars_lazy_report.html\")\n</code></pre>"},{"location":"usage/#deterministic-visuals-reproducible-sampling","title":"Deterministic visuals (reproducible sampling)","text":"<p>Use <code>random_seed</code> to make histogram sampling deterministic across runs.</p> <pre><code>from pysuricata import profile, ReportConfig\n\ncfg = ReportConfig()\ncfg.compute.random_seed = 42\nrep = profile(df, config=cfg)\n</code></pre>"},{"location":"usage/#programmatic-summary","title":"Programmatic summary","text":"<p>Ask for a compact JSON-like dictionary of stats:</p> <pre><code>from pysuricata import summarize\nsummary = summarize(df)\nprint(summary[\"dataset\"])           # rows_est, cols, missing_cells, duplicates, top-missing\nprint(summary[\"columns\"][\"amount\"]) # per-column stats by type\n</code></pre>"},{"location":"usage/#processed-bytes-and-timing","title":"Processed bytes and timing","text":"<p>The report displays: - Processed bytes (\u2248): total bytes handled across chunks (not peak RSS) - Precise generation time in seconds (e.g., 0.02s)</p>"},{"location":"usage/#end-to-end-minimal-example","title":"End-to-end minimal example","text":"<pre><code>import pandas as pd\nfrom pysuricata import profile, ReportConfig\n\ndf = pd.DataFrame(\n    {\n        \"amount\": [1.0, 2.5, None, 4.0, 5.5],\n        \"country\": [\"US\", \"US\", \"DE\", None, \"FR\"],\n        \"ts\": pd.to_datetime([\"2021-01-01\", \"2021-01-02\", None, \"2021-01-04\", \"2021-01-05\"]),\n        \"flag\": [True, False, True, None, False],\n    }\n)\n\ncfg = ReportConfig()\ncfg.compute.random_seed = 0\nrep = profile(df, config=cfg)\nrep.save_html(\"report.html\")\n</code></pre>"}]}